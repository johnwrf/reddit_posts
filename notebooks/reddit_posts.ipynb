{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b179d8",
   "metadata": {},
   "source": [
    "# Reddit Posts\n",
    "This notebook allows to interaact with the reddit posts application using different configurations as well as to observe the result sets. The notebook does comparisons of new Reddit posts vs the Reddit posts from the previous execution.\n",
    "- new posts since last execution\n",
    "- posts that are no longer in top 75 since last execution\n",
    "- posts whose scores changed since last execution\n",
    "\n",
    "A markdown section has been added above each notebook cell explaining what it does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef6037",
   "metadata": {},
   "source": [
    "## Constants\n",
    "Constants are defined to track the path locations in the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2430f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/Users/johnrojas/Development/vcs/github/johnwrf/reddit_posts'\n",
    "SRC_PATH = '/Users/johnrojas/Development/vcs/github/johnwrf/reddit_posts/src'\n",
    "DATA_PATH = '/Users/johnrojas/Development/vcs/github/johnwrf/reddit_posts/data'\n",
    "\n",
    "NEW_POSTS_LISTING = \"new\"\n",
    "TOP_POSTS_LISTING = \"top\"\n",
    "\n",
    "NEW_POSTS_COUNT = 100\n",
    "TOP75_POSTS_COUNT = 75\n",
    "\n",
    "POST_COLUMNS = [\n",
    "    \"author_fullname\",\n",
    "    \"title\",\n",
    "    \"name\",\n",
    "    \"score\",\n",
    "    \"created\",\n",
    "    \"view_count\",\n",
    "    \"id\",\n",
    "    \"author\",\n",
    "    \"url\",\n",
    "    \"created_utc\"\n",
    "    ]\n",
    "\n",
    "POST_COLUMNS_X = {POST_COLUMNS[i]+\"_x\":POST_COLUMNS[i] for i in range(len(POST_COLUMNS))}\n",
    "POST_COLUMNS_Y = {POST_COLUMNS[i]+\"_y\":POST_COLUMNS[i] for i in range(len(POST_COLUMNS))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f9609",
   "metadata": {},
   "source": [
    "## Imports and configuration\n",
    "This section imports dependant modules and makes sure the notebook has access to the Reddit Posts application source.\n",
    "Finally the logging module is configured so that application log statements are visible when each notbook cell is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22d2501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/johnrojas/Development/vcs/github/johnwrf/reddit_posts/notebooks', '/usr/local/anaconda3/lib/python39.zip', '/usr/local/anaconda3/lib/python3.9', '/usr/local/anaconda3/lib/python3.9/lib-dynload', '', '/usr/local/anaconda3/lib/python3.9/site-packages', '/usr/local/anaconda3/lib/python3.9/site-packages/aeosa', '/Users/johnrojas/Development/vcs/github/johnwrf/reddit_posts/src', '/Users/johnrojas/Development/vcs/github/johnwrf/reddit_posts/src', '/Users/johnrojas/Development/vcs/github/johnwrf/reddit_posts/src', '/Users/johnrojas/Development/vcs/github/johnwrf/reddit_posts/src', '/Users/johnrojas/Development/vcs/github/johnwrf/reddit_posts/src']\n"
     ]
    }
   ],
   "source": [
    "import datatable as dt\n",
    "import pandas as pd\n",
    "\n",
    "# patch to import source code\n",
    "import sys\n",
    "sys.path.append(SRC_PATH)\n",
    "print(sys.path)\n",
    "\n",
    "from apis.reddit.reddit_posts import RedditPosts\n",
    "from apis.io.post_io import load_posts, save_posts\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4576f09",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load new posts\n",
    "\n",
    "This section loads the latest new posts and the new posts from the last execution\n",
    "\n",
    "Note that the same code is used to load both new posts and top posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "740a3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-23 11:37:29,591 [INFO] loaded latest new posts count 100\n",
      "2022-09-23 11:37:29,594 [INFO] loaded previous new posts count 100\n"
     ]
    }
   ],
   "source": [
    "reddit_new = RedditPosts(listing=NEW_POSTS_LISTING, limit=NEW_POSTS_COUNT, timeframe=\"hour\")\n",
    "new_posts = reddit_new.load(columns=POST_COLUMNS)\n",
    "logging.info(f\"loaded latest new posts count {new_posts.nrows}\")\n",
    "\n",
    "last_new_posts = load_posts(listing=NEW_POSTS_LISTING, columns=POST_COLUMNS, base_path=DATA_PATH)\n",
    "logging.info(f\"loaded previous new posts count {last_new_posts.nrows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca4856",
   "metadata": {},
   "source": [
    "## Load Top 75 posts\n",
    "\n",
    "This section loads the latest top 75 posts and the top 75 posts from the last execution\n",
    "\n",
    "Note that the same code is used to load both new posts and top posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2148afc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-23 11:37:32,647 [INFO] loaded latest top posts count 75\n",
      "2022-09-23 11:37:32,649 [INFO] loaded previous top posts count 75\n"
     ]
    }
   ],
   "source": [
    "reddit_top = RedditPosts(listing=TOP_POSTS_LISTING, limit=TOP75_POSTS_COUNT, timeframe=\"hour\")\n",
    "top_posts = reddit_top.load(columns=POST_COLUMNS)\n",
    "logging.info(f\"loaded latest top posts count {top_posts.nrows}\")\n",
    "\n",
    "last_top_posts = load_posts(listing=TOP_POSTS_LISTING, columns=POST_COLUMNS, base_path=DATA_PATH)\n",
    "logging.info(f\"loaded previous top posts count {last_top_posts.nrows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb97da",
   "metadata": {},
   "source": [
    "## Save posts\n",
    "This section saves the lastest new and top75 posts to files on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37cbb664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_posts(listing=NEW_POSTS_LISTING, posts=new_posts, base_path=DATA_PATH)\n",
    "save_posts(listing=TOP_POSTS_LISTING, posts=top_posts, base_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62fcf7e",
   "metadata": {},
   "source": [
    "## Determine new posts since last run\n",
    "A pandas dataframe is used because the datatable df does not yet support left/right outer joins\n",
    "The datatable df can easily be converted to a pandas df\n",
    "The pandas merge function is then used with the indicator=True option, \n",
    "which generates a new \"_merge\" column, with values: left_only, right_only and both\n",
    "\n",
    "Once the merge is performed, all the latest new posts are marked with \"_merge\"=\"left_only\", meaning those are the posts that only appeared in the latest results.\n",
    "\n",
    "Finally, column names are cleaned up and only the new posts data is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3166a31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "left_only     100\n",
       "right_only    100\n",
       "both            0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of    author_fullname_x                                            title_x  \\\n",
       "0        t2_acculm9t  what should I do with my hair? should I cut th...   \n",
       "1        t2_5l5ozyqq              A warning message exists for a reason   \n",
       "2        t2_sr2a6562              I saw this cute girl in a coffee shop   \n",
       "3         t2_vqzbu2g                     They're praying on my downfall   \n",
       "4        t2_ed9lzz4d        Galtier a une idée pour démarabouter le PSG   \n",
       "..               ...                                                ...   \n",
       "95       t2_dfmms38c  [FOR HIRE] I do portrait and landscape illustr...   \n",
       "96       t2_6fz93vjt                              +10 Flame Tribe Lyn ?   \n",
       "97       t2_3dlemb4v  Book review -- BOLD VENTURES: Thirteen Tales o...   \n",
       "98       t2_m1mag9xy  Rivian R1T Drag Racing a Tesla Model 3 Perform...   \n",
       "99       t2_brd6e4v9                  Iams 3.5-Pound Dry Cat Food $2.93   \n",
       "\n",
       "       name_x  score_x           created_x  view_count_x      id  \\\n",
       "0   t3_xm0nw4      1.0 2022-09-23 15:30:05           0.0  xm0nw4   \n",
       "1   t3_xm0nw5      1.0 2022-09-23 15:30:05           0.0  xm0nw5   \n",
       "2   t3_xm0nw3      1.0 2022-09-23 15:30:04           0.0  xm0nw3   \n",
       "3   t3_xm0nw2      1.0 2022-09-23 15:30:04           0.0  xm0nw2   \n",
       "4   t3_xm0nw1      1.0 2022-09-23 15:30:04           0.0  xm0nw1   \n",
       "..        ...      ...                 ...           ...     ...   \n",
       "95  t3_xm0noo      1.0 2022-09-23 15:29:53           0.0  xm0noo   \n",
       "96  t3_xm0nol      1.0 2022-09-23 15:29:53           0.0  xm0nol   \n",
       "97  t3_xm0nog      1.0 2022-09-23 15:29:53           0.0  xm0nog   \n",
       "98  t3_xm0nou      1.0 2022-09-23 15:29:52           0.0  xm0nou   \n",
       "99  t3_xm0noa      1.0 2022-09-23 15:29:52           0.0  xm0noa   \n",
       "\n",
       "           author_x                                              url_x  \\\n",
       "0      Great-Ad7157                https://i.redd.it/t1hl7ws7nmp91.jpg   \n",
       "1        GoodGuy147  https://www.reddit.com/r/wildrift/comments/xm0...   \n",
       "2    Coffeefungirls  https://www.reddit.com/r/relationship_advice/c...   \n",
       "3       roshiturtle                https://i.redd.it/294arw52nmp91.png   \n",
       "4    code_hunter_cc  https://www.reddit.com/r/football_leads/commen...   \n",
       "..              ...                                                ...   \n",
       "95    hieuthehooman              https://www.reddit.com/gallery/xm0noo   \n",
       "96          Ryoneru  https://www.reddit.com/r/FireEmblemHeroes/comm...   \n",
       "97       EdgarAlley                https://i.redd.it/kuz7afz0nmp91.jpg   \n",
       "98  JeffTechnically             https://youtube.com/shorts/kg93B7PRO6M   \n",
       "99   CouponingLady_  https://www.freestufffinder.com/iams-3-5-pound...   \n",
       "\n",
       "         created_utc_x author_fullname_y title_y name_y  score_y created_y  \\\n",
       "0  2022-09-23 15:30:05               NaN     NaN    NaN      NaN       NaT   \n",
       "1  2022-09-23 15:30:05               NaN     NaN    NaN      NaN       NaT   \n",
       "2  2022-09-23 15:30:04               NaN     NaN    NaN      NaN       NaT   \n",
       "3  2022-09-23 15:30:04               NaN     NaN    NaN      NaN       NaT   \n",
       "4  2022-09-23 15:30:04               NaN     NaN    NaN      NaN       NaT   \n",
       "..                 ...               ...     ...    ...      ...       ...   \n",
       "95 2022-09-23 15:29:53               NaN     NaN    NaN      NaN       NaT   \n",
       "96 2022-09-23 15:29:53               NaN     NaN    NaN      NaN       NaT   \n",
       "97 2022-09-23 15:29:53               NaN     NaN    NaN      NaN       NaT   \n",
       "98 2022-09-23 15:29:52               NaN     NaN    NaN      NaN       NaT   \n",
       "99 2022-09-23 15:29:52               NaN     NaN    NaN      NaN       NaT   \n",
       "\n",
       "   view_count_y author_y url_y created_utc_y     _merge  \n",
       "0           NaN      NaN   NaN           NaT  left_only  \n",
       "1           NaN      NaN   NaN           NaT  left_only  \n",
       "2           NaN      NaN   NaN           NaT  left_only  \n",
       "3           NaN      NaN   NaN           NaT  left_only  \n",
       "4           NaN      NaN   NaN           NaT  left_only  \n",
       "..          ...      ...   ...           ...        ...  \n",
       "95          NaN      NaN   NaN           NaT  left_only  \n",
       "96          NaN      NaN   NaN           NaT  left_only  \n",
       "97          NaN      NaN   NaN           NaT  left_only  \n",
       "98          NaN      NaN   NaN           NaT  left_only  \n",
       "99          NaN      NaN   NaN           NaT  left_only  \n",
       "\n",
       "[100 rows x 20 columns]>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_this_run = new_posts.to_pandas()\n",
    "df_last_run = last_new_posts.to_pandas()\n",
    "df_new_posts = pd.merge(df_this_run, df_last_run, on=['id'], how=\"outer\", indicator=True)\n",
    "display(df_new_posts.groupby(['_merge'])['_merge'].count())\n",
    "\n",
    "df_new_since_last = df_new_posts[df_new_posts['_merge'] == 'left_only']\n",
    "df_new_since_last = df_new_since_last.rename(POST_COLUMNS_X, axis=1)\n",
    "df_new_since_last = df_new_since_last[POST_COLUMNS]\n",
    "df_new_since_last.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9212521",
   "metadata": {},
   "source": [
    "## Determine posts no longer in top 75 since last run\n",
    "A pandas dataframe is used because the datatable df does not yet support left/right outer joins\n",
    "The datatable df can easily be converted to a pandas df\n",
    "The pandas merge function is then used with the indicator=True option, \n",
    "which generates a new \"_merge\" column, with values: left_only, right_only and both\n",
    "\n",
    "Once the merge is performed, the previous posts that were part of top 75 are marked with \"_merge\"=\"right_only\", meaning those are the posts that no longer appeared in the top75 results.\n",
    "\n",
    "Finally, column names are cleaned up and only the new posts data is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00f89aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "left_only     75\n",
       "right_only    75\n",
       "both           0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     author_fullname                                              title  \\\n",
       "75      t2_6oaefno3  KaiCenat reacts to Ice Posieden tweet about Mi...   \n",
       "76      t2_gfd0vegb  Sliker's ex gf on living with the Austin texas...   \n",
       "77       t2_6viux77  Adrianah tweets thread with 5 more ppl sharing...   \n",
       "78      t2_pjosalwp                          2.3 Trillion Interception   \n",
       "79      t2_4dhra4m3                              Ranger's Rank Shakeup   \n",
       "..              ...                                                ...   \n",
       "145     t2_6x507zyd                  Yeah it's already been 2 years...   \n",
       "146     t2_73lxcajb                                        Every time…   \n",
       "147     t2_2z06hyp3                 Starting a Nelf in Classic be like   \n",
       "148     t2_bpy1i16m                                       No Caption..   \n",
       "149     t2_a5j7p838                                      Cursed Pacman   \n",
       "\n",
       "          name  score             created view_count      id  \\\n",
       "75   t3_xj02cl  392.0 2022-09-20 05:26:21      False  xj02cl   \n",
       "76   t3_xizp4b  219.0 2022-09-20 05:06:08      False  xizp4b   \n",
       "77   t3_xj043d  144.0 2022-09-20 05:29:03      False  xj043d   \n",
       "78   t3_xizhk4  119.0 2022-09-20 04:55:12      False  xizhk4   \n",
       "79   t3_xj001x  114.0 2022-09-20 05:22:46      False  xj001x   \n",
       "..         ...    ...                 ...        ...     ...   \n",
       "145  t3_xj022z   25.0 2022-09-20 05:25:58      False  xj022z   \n",
       "146  t3_xizxvu   25.0 2022-09-20 05:19:33      False  xizxvu   \n",
       "147  t3_xizrjw   23.0 2022-09-20 05:09:52      False  xizrjw   \n",
       "148  t3_xizj0f   23.0 2022-09-20 04:57:24      False  xizj0f   \n",
       "149  t3_xizktq   24.0 2022-09-20 05:00:08      False  xizktq   \n",
       "\n",
       "                   author                                                url  \\\n",
       "75       HeirOfEverything  https://clips.twitch.tv/ExuberantBlatantNugget...   \n",
       "76      Amazing_Army_1803  https://clips.twitch.tv/DepressedFragileOyster...   \n",
       "77          finecherrypie  https://clips.twitch.tv/FreezingAthleticWolver...   \n",
       "78              sjcfheipe                    https://v.redd.it/ehauqu833yo91   \n",
       "79    LordOfKhaoticStorms  https://clips.twitch.tv/CrowdedAffluentHumanDa...   \n",
       "..                    ...                                                ...   \n",
       "145            _KOKUHAKU_                https://i.redd.it/d9q08adp8yo91.png   \n",
       "146        DeletedKingdom                https://i.redd.it/ot4zs6bk7yo91.jpg   \n",
       "147              heaxdini                https://i.redd.it/cfliom6u5yo91.jpg   \n",
       "148  Lower-Bodybuilder-16                https://i.redd.it/bg9jnwsl3yo91.jpg   \n",
       "149         No-Thanks1916                https://i.redd.it/28xxkv0mlzo91.jpg   \n",
       "\n",
       "            created_utc  \n",
       "75  2022-09-20 05:26:21  \n",
       "76  2022-09-20 05:06:08  \n",
       "77  2022-09-20 05:29:03  \n",
       "78  2022-09-20 04:55:12  \n",
       "79  2022-09-20 05:22:46  \n",
       "..                  ...  \n",
       "145 2022-09-20 05:25:58  \n",
       "146 2022-09-20 05:19:33  \n",
       "147 2022-09-20 05:09:52  \n",
       "148 2022-09-20 04:57:24  \n",
       "149 2022-09-20 05:00:08  \n",
       "\n",
       "[75 rows x 10 columns]>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_this_run = top_posts.to_pandas()\n",
    "df_last_run = last_top_posts.to_pandas()\n",
    "df_top_posts = pd.merge(df_this_run, df_last_run, on=['id'], how=\"outer\", indicator=True)\n",
    "display(df_top_posts.groupby(['_merge'])['_merge'].count())\n",
    "\n",
    "df_no_longer_top75 = df_top_posts[df_top_posts['_merge'] == 'right_only']\n",
    "df_no_longer_top75 = df_no_longer_top75.rename(POST_COLUMNS_Y, axis=1)\n",
    "df_no_longer_top75 = df_no_longer_top75[POST_COLUMNS]\n",
    "df_no_longer_top75.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6e12",
   "metadata": {},
   "source": [
    "## Determine posts whose score changed\n",
    "To determine posts whose scores changed, we combine the new and top 75 posts, drop duplicates.\n",
    "Then, we filter the posts that appeared during both program executions and where the score changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f222c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>score_y</th>\n",
       "      <th>score_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, score, score_y, score_change]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.concat([df_top_posts, df_new_posts])\n",
    "df_scores.drop_duplicates(subset=['id'])\n",
    "\n",
    "df_scores = df_scores[(df_scores['_merge'] == 'both') & (df_scores['score_x'] != df_scores['score_y'])]\n",
    "\n",
    "df_scores = df_scores.rename(POST_COLUMNS_X, axis=1)\n",
    "df_scores = df_scores[POST_COLUMNS+['score_y']]\n",
    "df_scores['score_change'] = df_scores.score - df_scores.score_y\n",
    "df_scores[['title','score','score_y','score_change']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
